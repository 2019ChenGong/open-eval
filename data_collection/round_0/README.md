# Round 0: Data Synthesis (June 2023)

## Sourcing Data from GPT-4 with Seed Examples
We used GPT-4 to generate data for this round. The data was generated by providing GPT-4 with seed examples from ODEX and few-shot expected examples. The seed examples were provided in the form of a prompt. The prompt was designed to guide GPT-4 to generate data that is similar to the seed examples. The data generated by GPT-4 was then manually reviewed to ensure that it is relevant to the prompt and free of errors. To perform this step, please run the following command:
```bash
python data_synthesis.py
```
You can view all generated data for each ODEX split in the `gpt4odex/` folder.
All valid data is stored in the `OpenEval_gpt4.jsonl`.

## Obfuscation and Perturbation
To avoid the ambiguity of the data generated by GPT-4, we applied obfuscation and perturbation techniques to the generated data. This step was performed to ensure that the data is challenging and requires reasoning to solve. The obfuscation and perturbation techniques used in this round include:
- Entry Point Obfuscation: The naming of the entry point is formatted in "f_{entry_point_id}".
- Docstring Perturbation: The docstring is perturbed based on the same setting of [ReCode](https://github.com/amazon-science/recode). Specifically, we applied back-translation to rephrase the NL context in the docstring.

The perturbed data is stored in the `OpenEval_perturbed.jsonl`.

## Classifying Data for Annotation
The generated data was classified into a few categories to align annotators' preferences. To perform this step, please run the following command:
```bash
python data_classify.py
```
The classified data is stored in the `OpenEval_perturbed_class.jsonl`.