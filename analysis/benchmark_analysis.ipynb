{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown 1aaOaAM0iidmkR0mHkPOIwddpkpzBmlWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import json\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from numpy import mean, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_apis(code):\n",
    "    tree = ast.parse(code)\n",
    "    api_list = []\n",
    "    imported_modules = {}\n",
    "\n",
    "    class ApiExtractor(ast.NodeVisitor):\n",
    "        def visit_Import(self, node):\n",
    "            for alias in node.names:\n",
    "                module_name = alias.name\n",
    "                alias_name = alias.asname or alias.name\n",
    "                imported_modules[alias_name] = module_name\n",
    "                # Add submodule and top-level module\n",
    "                submodule_parts = module_name.split('.')\n",
    "                for i in range(1, len(submodule_parts) + 1):\n",
    "                    submodule = '.'.join(submodule_parts[:i])\n",
    "                    imported_modules[submodule] = submodule\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_ImportFrom(self, node):\n",
    "            module = node.module\n",
    "            if module:\n",
    "                for alias in node.names:\n",
    "                    full_name = f'{module}.{alias.name}'\n",
    "                    alias_name = alias.asname or alias.name\n",
    "                    imported_modules[alias_name] = full_name\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Attribute(self, node):\n",
    "            if isinstance(node.value, ast.Name) and node.value.id in imported_modules:\n",
    "                base_module = imported_modules[node.value.id]\n",
    "                api_call = f\"{base_module}.{node.attr}\"\n",
    "                if api_call not in api_list:\n",
    "                    api_list.append(api_call)\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Call(self, node):\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                attr_parts = []\n",
    "                current = node.func\n",
    "                while isinstance(current, ast.Attribute):\n",
    "                    attr_parts.append(current.attr)\n",
    "                    current = current.value\n",
    "\n",
    "                if isinstance(current, ast.Name) and current.id in imported_modules:\n",
    "                    base_module = imported_modules[current.id]\n",
    "                    attr_parts.append(base_module)\n",
    "                    attr_parts.reverse()\n",
    "                    api_call = '.'.join(attr_parts)\n",
    "                    if api_call not in api_list:\n",
    "                        api_list.append(api_call)\n",
    "            elif isinstance(node.func, ast.Name) and node.func.id in imported_modules:\n",
    "                api_call = imported_modules[node.func.id]\n",
    "                if api_call not in api_list:\n",
    "                    api_list.append(api_call)\n",
    "\n",
    "            self.generic_visit(node)\n",
    "\n",
    "    ApiExtractor().visit(tree)\n",
    "    return list(set(api_list))  # Remove duplicates\n",
    "\n",
    "def count_test_cases(class_string):\n",
    "    # Parse string containing class definition into an AST tree\n",
    "    tree = ast.parse(class_string)\n",
    "\n",
    "    # Function to check if a function node in AST represents a test case\n",
    "    def is_test_method(node):\n",
    "        return isinstance(node, ast.FunctionDef) and node.name.startswith('test_')\n",
    "\n",
    "    # Initialize a count of test methods\n",
    "    test_method_count = 0\n",
    "\n",
    "    # Traverse AST tree\n",
    "    for node in ast.walk(tree):\n",
    "        # Increment count if node is a test method\n",
    "        if is_test_method(node):\n",
    "            test_method_count += 1\n",
    "\n",
    "    return test_method_count\n",
    "\n",
    "def extract_sample_apis(sample):\n",
    "    if sample[\"library\"]:\n",
    "        compiled_content = sample[\"test_start\"].split(\"\\ndef check\")[0].strip()+\"\\n\\n\"\\\n",
    "                +sample[\"prompt\"]+sample[\"canonical_solution\"]\n",
    "        compiled_content = compiled_content.replace(\"\\t\",\"    \")\n",
    "        return extract_apis(compiled_content)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_data = [json.loads(l) for l in open(\"../data/open-eval.jsonl\").read().splitlines()]\n",
    "stack_data = [json.loads(l) for l in open(\"stack-dedup-python-lib-api.json\").read().splitlines()]\n",
    "odex_data = [json.loads(l) for file in glob(\"../data_collection/round_0/odex/*.jsonl\") for l in open(file).read().splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](benchmark_length.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Test Cases: 5.9\n",
      "Average Prompt Chars: 1117.7\n",
      "Average Prompt Lines: 32.7\n",
      "Average Solution Chars: 467.3\n",
      "Average Solution Lines: 13.1\n"
     ]
    }
   ],
   "source": [
    "# Average Number of Test Cases\n",
    "print(\"Average Number of Test Cases:\", round(mean([count_test_cases(b[\"test\"]) for b in benchmark_data]),1))\n",
    "# Average Prompt Chars\n",
    "print(\"Average Prompt Chars:\", round(mean([len(b[\"prompt\"]) for b in benchmark_data]),1))\n",
    "# Average Prompt Lines\n",
    "print(\"Average Prompt Lines:\", round(mean([b[\"prompt\"].count(\"\\n\") for b in benchmark_data]),1))\n",
    "# Averge Solution Chars\n",
    "print(\"Average Solution Chars:\", round(mean([len(b[\"canonical_solution\"]) for b in benchmark_data]),1))\n",
    "# Average Solution Lines\n",
    "print(\"Average Solution Lines:\", round(mean([b[\"canonical_solution\"].count(\"\\n\") for b in benchmark_data]),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lib2domain.json\") as f:\n",
    "    lib2domain = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Libraries in the Stack: 765602\n",
      "Average Number of Libraries Per File in The Stack: 3.1\n",
      "Total Number of APIs in The Stack: 14959933\n",
      "Average Number of API Calls Per File in The Stack: 9.0\n"
     ]
    }
   ],
   "source": [
    "# Total Libraries in Stack\n",
    "print(\"Total Libraries in Stack:\", len(set([lib for l in stack_data for lib in l[\"library\"]])))\n",
    "# Average Number of Libraries in Stack\n",
    "print(\"Average Number of Libraries Per File in Stack:\", round(mean([len(l[\"library\"]) for l in stack_data]),1))\n",
    "# Total Number of APIs in Stack\n",
    "print(\"Total Number of APIs in Stack:\", len(set([api for l in stack_data for api in l[\"api\"]])))\n",
    "# Average Number of API Calls in Stack\n",
    "print(\"Average Number of API Calls Per File in Stack:\", round(mean([len(l[\"api\"]) for l in stack_data]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Libraries in OpenEval: 112\n",
      "Average Number of Libraries Per Tasks: 2.7\n",
      "Total Number of APIs in OpenEval: 507\n",
      "Average Number of API Calls Per Tasks: 4.2\n",
      "Domain Distribution of Libraries in OpenEval: [('System', 27), ('General', 25), ('Network', 25), ('Computation', 15), ('Cryptography', 10), ('Time', 5), ('Visualization', 5)]\n",
      "Domain Freq of Stack Counter for OpenEval: [('Computation', 508), ('General', 274), ('System', 255), ('Visualization', 187), ('Network', 101), ('Cryptography', 60), ('Time', 52)]\n",
      "Total Number of Different Lib Combo in OpenEval: 308\n",
      "Total Number of Different API Combo in OpenEval: 502\n",
      "Total Number of Different Domain Combo in OpenEval: 117\n"
     ]
    }
   ],
   "source": [
    "# Total Libraries in OpenEval\n",
    "print(\"Total Libraries in OpenEval:\", len(set([lib for b in benchmark_data for lib in b[\"libs\"]])))\n",
    "# Average Number of Libraries in OpenEval\n",
    "print(\"Average Number of Libraries Per Tasks:\", round(mean([len(b[\"libs\"]) for b in benchmark_data]),1))\n",
    "benchmark_lib = set([lib for b in benchmark_data for lib in b[\"libs\"]])\n",
    "# Total Number of APIs in OpenEval\n",
    "print(\"Total Number of APIs in OpenEval:\", len(set([api for b in benchmark_data for api in b[\"apis\"]])))\n",
    "# Average Number of API Calls in OpenEval\n",
    "print(\"Average Number of API Calls Per Tasks:\", round(mean([len(b[\"apis\"]) for b in benchmark_data]),1))\n",
    "# Domain Distribution of Libraries in OpenEval\n",
    "print(\"Domain Distribution of Libraries in OpenEval:\", Counter([lib2domain[lib] for lib in benchmark_lib]).most_common())\n",
    "# Domain Freq of Stack Counter for OpenEval\n",
    "print(\"Domain Freq of Stack Counter for OpenEval:\", Counter([lib2domain[lib] for b in benchmark_data for lib in b[\"libs\"]]).most_common())\n",
    "# Total Number of Different Lib Combo in OpenEval\n",
    "print(\"Total Number of Different Lib Combo in OpenEval:\", len(set([tuple(sorted(b[\"libs\"])) for b in benchmark_data])))\n",
    "# Total Number of Different API Combo in OpenEval\n",
    "print(\"Total Number of Different API Combo in OpenEval:\", len(set([tuple(sorted(b[\"apis\"])) for b in benchmark_data])))\n",
    "# Total Number of Different Domain Combo in OpenEval\n",
    "print(\"Total Number of Different Domain Combo in OpenEval:\", len(set([tuple(sorted([lib2domain[lib] for lib in b[\"libs\"]])) for b in benchmark_data])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
